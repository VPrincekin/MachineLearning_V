### 决策树Decisiontree算法介绍

### 1.算法简介

决策树是一种简单高效并且具有强解释性的模型，广泛应用于数据分析领域。其本质是一颗由多个判断节点组成的树。
决策树是一种非参数的监督学习方法，可用于分类和回归的应用中。旨在通过数据学习出简单的决策规则来创建模型，进而预测和判定目标变量的结果。

熵(entropy)指的是体系的混乱的程度，在不同的学科中也有引申出的更为具体的定义，是各领域十分重要的参量。

信息熵(香农熵)：是一种信息的度量方式，表示信息的混乱程度，也就是说：信息越有序，信息熵越低。

信息增益： 在划分数据集前后信息发生的变化称为信息增益。

### 2.算法步骤

```
检测数据集中的每个子项是否属于同一分类:
    If so return 类标签
    Else:
        寻找划分数据集的最好特征（划分之后信息熵最小，也就是信息增益最大的特征）
        划分数据集
        创建分支节点
            for 每个划分的子集
                调用函数 createBranch （创建分支的函数）并增加返回结果到分支节点中
        return 分支节点
```

### 3.算法优缺点

1.优点

计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据

2.缺点

可能会产生过度匹配问题

### 4.算法优化

[决策树算法原理](http://www.cnblogs.com/pinard/p/6050306.html)




